{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3a840a8ded35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "#import mglearn\n",
    "#from matplotlib import pyplot as plt\n",
    "#from fpdf import FPDF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Cross validation scores: [ 1.          0.83333333  1.          1.          0.93333333]\nAverage CV score: 0.95\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "logreg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv = kfold)\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "print(\"Average CV score: {:.2f}\".format(scores.mean()))\n",
    "#if variance of scores is high: 1. model is dependent on particular folds\n",
    "#2. or consequence of small size of dataset\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test set score: 0.97\nBest parameters: {'C': 100, 'gamma': 0.01}\nBest CV score: 0.97\nBest estimator:\nSVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Grid search allows us to try all possible combinations of hyperparameters\n",
    "#splitting the data into training/valid/test is sensitive to how the data is split\n",
    "#For a better estimate, use CV + GridSearch\n",
    "param_grid = {\"C\": [ 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "              \"gamma\": [ 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "\n",
    "#GridSearchCV uses CV but we still need to split the data into training/testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "\n",
    "grid_search.fit(X_train, y_train)  #searches for best parameters and automatically fits \n",
    "                                    # a new model on the whole training dataset w best hyperparameters\n",
    "#this automatically uses a training/validation set\n",
    "\n",
    "#GridSearch class provides convenient interface to access the retrained model via\n",
    "#the predict and score methods.\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test,y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best CV score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "#Best score is different than the generalization performance computed by score method\n",
    "#best_score stores the mean cross-validation accuracy, with cross validation performed on training set\n",
    "\n",
    "#to access the actual mode that was found:\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "\n",
    "#analyzing the results of cross-validation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#mglearn.plots.plot_grid_search_overview()\n",
    "#plt.savefig(\"Process_Overview.pdf\", bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "#display(results.head())\n",
    "scores = np.array(results.mean_test_score).reshape(6,6) #extract the mean validation scores\n",
    "#plot the mean cross-validation scores\n",
    "mglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid['gamma'],\n",
    "                      ylabel='C', yticklabels=param_grid['C'], cmap = 'viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each point in the heat map corresponds to one run of cross-validation with a particular setting. \n",
    "Light colours correspond to high accuracy/Dark -> low accuracy. The plots shows SVC is senstitive to \n",
    "settings of the parameter. This implies parameters are very important for obtaining good performance.\n",
    "Also it's important to observe the ranges for\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we investiage metrics for Multiclass Classification:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()\n",
    "lr = LogisticRegression()\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, random_state=0)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(y_test, pred)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}